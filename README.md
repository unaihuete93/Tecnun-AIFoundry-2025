# Azure Foundry Labs

# Introduction to Azure Foundry

## Scenarios Covered
- Overview of Azure Foundry
- Models and Capabilities
- Calling Models from Azure Foundry and using different techniques
    - System Message
    - Parameters
    - Few Shot Examples
    - Conversation History

## EXERCISES TO BE UPLOADED
There will be sections in the document were the student will have to upload a file to ADI to show they have completed the exercise.


### TASK 1 - Setting up Azure Foundry

In this task you will see the Azure AI Foundry that has been set up for you. You will also see the models that have been deployed to this Foundry.

If you open the Azure Portal (https://portal.azure.com) and navigate to the resource group `AzureFoundry-Grado-Sept`, you will see a resource called `foundryproject-tecnun-resource`. This is the Azure Foundry resource that has been set up for you.

Open the resource and expand all the options on the left column. You will see the following options:

![Azure Foundry Resource](images/Foundry-Portal.png)

- **Overview**: This is the overview of the Azure Foundry resource. You can see the location, resource group, subscription, region and other details about the resource.
    

- **Access Control (IAM)**: This is where you can manage access to the Azure Foundry resource. You can add or remove users and assign roles to them.

    > NOTE: You have been given the **Azure AI User** role for this resource. You will be able to use the models deployed to this Foundry, but you will not be able to manage the resource.

- **Keys and Endpoint**: This is where you can find the keys and endpoint for the Azure Foundry resource. You will need these to connect to the Foundry from your application.

- **Networking**: This is where you can manage the networking settings for the Azure Foundry resource. You can configure virtual networks, private endpoints, and other networking settings.

- **Monitoring**: This is where you can monitor the Azure Foundry resource. You can view metrics, logs, and other monitoring data.

From the overview page, click on the link to the Foundry Portal (https://ai.azure.com). This will take you to the Azure Foundry portal.

![Azure Foundry Resource](images/Foundry-Portal.png)

The Foundry can be used for several scenarios, including:
- Model Management: You can deploy, manage, and monitor AI models in a centralized location.
- Playground: You can test and evaluate different AI models and configurations.
- Projects: You can create projects to organize and manage your AI models and resources.
- Fine Tuning: You can fine-tune pre-trained models to better suit your specific use cases.
- Evaluation: You can evaluate the performance of your AI models using various metrics and benchmarks.
- More....

In this lab, we will focus on the **Model Catalog** and **Playgrounds** sections of the Foundry.

### TASK 2 - Exploring the Model Catalog

In this task, you will explore the Model Catalog in the Azure Foundry portal. The Model Catalog is where you can find all the AI models that have been deployed to the Foundry.

Click on the **Model Catalog** option in the left column. You will see a list of all the models that have been deployed to the Foundry.

![Model Catalog](images/Catalog.png)

You will see Azure AI Foundry offers so many different types and providers of models:

- Providers like: Azure OpenAI, Microsoft, Hugging Face, Cohere, etc.
- Types like: Chat, Text Generation, Embeddings, Image Generation, etc.

Search for `gpt-4.1` in the search bar:

![Search for GPT-4](images/gpt4.1.png)

Focus on the 3 model options given for GPT-4.1:
- GPT-4.1 (Azure OpenAI)
- GPT-4.1-mini (Microsoft)
- GPT-4.1-nano (Microsoft)

This shows the different model variations that are available for GPT-4.1. Remember the main differences discussed in class between LLM and SLM models. The GPT-4.1 (Azure OpenAI) is a Large Language Model (LLM) while the GPT-4.1-mini and GPT-4.1-nano are Small Language Models (SLM).

Click on the `GPT-4.1 (Azure OpenAI)` model. You will see the details of the model, including the description, version, provider, and other details.

![GPT-4.1 Model Details](images/Model-Details.png)

 - **Description**: This is a brief description of the model. It provides an overview of the model's capabilities and use cases.
 - **Version**: This is the version of the model. It indicates the specific iteration of
    the model that is deployed.
- **Input/Outputs**: This section provides information about the input and output formats of the model. It describes the expected input data and the format of the output generated by the model.
- **Pricing**: This section provides information about the pricing of the model. It describes the cost associated with using the model, including any usage-based fees or subscription plans.
- **Regions**: This section provides information about the regions where the model is available. It describes the geographic locations where the model can be accessed and used.

Take a look at the **Benchmarks** tab. This tab provides information about the performance of the model on various benchmarks. You can see the results of the model on different tasks and datasets.

Lets compare the three models mentioned before: GPT-4.1 (Azure OpenAI), GPT-4.1-mini (Microsoft), and GPT-4.1-nano (Microsoft).

Click on **compare with more models** , delete existing ones and select the other two models. You will see a comparison of the three models, including their performance on various benchmarks.

For example, you can see the Quality/Cost comparison chart:

![Model Comparison](images/benchmark.png)

#### TASK 2 - EXERCISE

1. Take a screenshot of the comparison chart for the three GPT-4.1 models, comparing Quality/Latency and upload it to ADI as proof of completing this exercise. **The picture must show the USERNAME/EMAIL to be taken as VALID**

Example:

![Model Comparison](images/TASK2-exercise.png)





